{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data science assignment #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 사이언스 과제#2는 주어진 `train set`을 사용하여 decision tree를 만들어 `test set`에 잘 들어맞게 만드는 것이다.\n",
    "먼저 주어진 데이터들을 확인해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>car_evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>5more</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying maint  doors persons lug_boot safety car_evaluation\n",
       "0   high  high      3       4      big    low          unacc\n",
       "1    med  high      2       2    small    med          unacc\n",
       "2    low   med  5more       2      big   high          unacc"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/dt_train1.txt', sep='\\t')\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>med</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety\n",
       "0    med  vhigh     2       4      med    med\n",
       "1    low   high     4       4    small    low\n",
       "2   high  vhigh     4       4      med    med"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('./data/dt_test1.txt', sep='\\t')\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>car_evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>med</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety car_evaluation\n",
       "0    med  vhigh     2       4      med    med          unacc\n",
       "1    low   high     4       4    small    low          unacc\n",
       "2   high  vhigh     4       4      med    med          unacc"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = pd.read_csv('./test/dt_answer1.txt', sep='\\t')\n",
    "answer.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 데이터들이 어떠한 칼럼을 가지고 있고, 어떤 값을 가지고 있는지 확인할 수 있다.\n",
    "\n",
    "가장 먼저 확인해야 할 일은 데이터들이 어떠한 특징을 가지고 있는지이다. 먼저 categorical data는 다루기 힘들기 때문에 numeric으로 바꿔주자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우리가 예측해야하는 칼럼의 이름을 y_label이라고 하자\n",
    "y_label = list(set(train.columns) - set(test.columns))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>car_evaluation</th>\n",
       "      <th>doors</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>maint</th>\n",
       "      <th>persons</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  car_evaluation  doors  lug_boot  maint  persons  safety\n",
       "0       0               0      0         0      0        0       0\n",
       "1       1               0      1         1      0        1       1\n",
       "2       2               0      2         0      1        1       2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 칼럼에 pandas.factorize를 적용함으로써 쉽게 numeric으로 바꿀 수 있다.\n",
    "df = pd.concat([train, test, answer]).apply(lambda x: pd.factorize(x)[0])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factorize를 적용하기 위해 train, test, answer을 합쳤으므로, 다시 나눠준다.\n",
    "x_train = df.iloc[:len(train)].drop(y_label, axis=1)\n",
    "y_train = df.iloc[:len(train)][y_label]\n",
    "x_test = df.iloc[len(train):len(train)+len(test)].drop(y_label, axis=1)\n",
    "ans = df.iloc[len(train)+len(test):][y_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x_test.shape == test.shape\n",
    "assert len(ans) == len(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 Classifier로 각각 어떤 결과들이 나오는지 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.random.RandomState(1000)\n",
    "models = [DecisionTreeClassifier(random_state=state),\n",
    "          RandomForestClassifier(n_estimators=256, random_state=1000),\n",
    "          ExtraTreesClassifier(random_state=state),\n",
    "          AdaBoostClassifier(DecisionTreeClassifier(random_state=state)),\n",
    "          BaggingClassifier(random_state=state),\n",
    "          ExtraTreeClassifier(random_state=state),\n",
    "          GradientBoostingClassifier(random_state=state),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(classifier):\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    count = sum([pred == ans for pred, ans in zip(y_pred, ans)])\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'> 328\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'> 322\n",
      "<class 'sklearn.ensemble.forest.ExtraTreesClassifier'> 299\n",
      "<class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'> 328\n",
      "<class 'sklearn.ensemble.bagging.BaggingClassifier'> 329\n",
      "<class 'sklearn.tree.tree.ExtraTreeClassifier'> 275\n",
      "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'> 327\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    r = process(model)\n",
    "    print (model.__class__, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(groups, classes):\n",
    "    instances = float(sum([len(group) for group in groups]))\n",
    "    def _calc(group):\n",
    "        size = float(len(group))\n",
    "        score = sum([([r[-1] for r in group].count(val) / size) ** 2 for val in classes])\n",
    "        return (1. - score) * (size / instances)\n",
    "    return sum(map(_calc, filter(lambda g: len(g), groups)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(gini([[[1, 1], [1, 0]], [[1, 1], [1, 0]]], [0, 1]))\n",
    "print(gini([[[1, 0], [1, 0]], [[1, 1], [1, 1]]], [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, criterion, splitter, max_depth, max_features, max_leaf_nodes, random_state):\n",
    "        self.criterion = criterion\n",
    "        self.splitter = splitter\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.min_samples_split=2\n",
    "        self.min_samples_leaf=1\n",
    "        self.min_weight_fraction_leaf=0.\n",
    "        self.min_impurity_decrease=0.\n",
    "        self.min_impurity_split=None\n",
    "        self.class_weight=None\n",
    "        self.presort=False\n",
    "        \n",
    "    def fit():\n",
    "        n_samples, self.n_features_ = X.shape\n",
    "        y = np.atleast_1d(y)\n",
    "        expanded_class_weight = None\n",
    "        y = np.reshape(y, (-1, 1))\n",
    "        y = np.copy(y)\n",
    "        \n",
    "        self.n_outputs_ = y.shape[1]\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.n_classes_ = len(np.unique(y))\n",
    "        \n",
    "        max_depth = ((2 ** 31) - 1 if self.max_depth is None else self.max_depth)\n",
    "        max_leaf_nodes = (-1 if self.max_leaf_nodes is None else self.max_leaf_nodes)\n",
    "        \n",
    "        self.max_features = self.n_features_\n",
    "        \n",
    "        min_weight_leaf = (self.min_weight_fraction_leaf * n_samples)\n",
    "        min_impurity_split = 1e-7\n",
    "        presort = self.presort\n",
    "        criterion = self.criterion\n",
    "        \n",
    "        \n",
    "    def predict():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Build tree\n",
    "        criterion = self.criterion\n",
    "        if not isinstance(criterion, Criterion):\n",
    "            if is_classification:\n",
    "                criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
    "                                                         self.n_classes_)\n",
    "            else:\n",
    "                criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
    "                                                         n_samples)\n",
    "\n",
    "        SPLITTERS = SPARSE_SPLITTERS if issparse(X) else DENSE_SPLITTERS\n",
    "\n",
    "        splitter = self.splitter\n",
    "        if not isinstance(self.splitter, Splitter):\n",
    "            splitter = SPLITTERS[self.splitter](criterion,\n",
    "                                                self.max_features_,\n",
    "                                                min_samples_leaf,\n",
    "                                                min_weight_leaf,\n",
    "                                                random_state,\n",
    "                                                self.presort)\n",
    "\n",
    "        self.tree_ = Tree(self.n_features_, self.n_classes_, self.n_outputs_)\n",
    "\n",
    "        # Use BestFirst if max_leaf_nodes given; use DepthFirst otherwise\n",
    "        if max_leaf_nodes < 0:\n",
    "            builder = DepthFirstTreeBuilder(splitter, min_samples_split,\n",
    "                                            min_samples_leaf,\n",
    "                                            min_weight_leaf,\n",
    "                                            max_depth,\n",
    "                                            self.min_impurity_decrease,\n",
    "                                            min_impurity_split)\n",
    "        else:\n",
    "            builder = BestFirstTreeBuilder(splitter, min_samples_split,\n",
    "                                           min_samples_leaf,\n",
    "                                           min_weight_leaf,\n",
    "                                           max_depth,\n",
    "                                           max_leaf_nodes,\n",
    "                                           self.min_impurity_decrease,\n",
    "                                           min_impurity_split)\n",
    "\n",
    "        builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
    "\n",
    "        if self.n_outputs_ == 1:\n",
    "            self.n_classes_ = self.n_classes_[0]\n",
    "            self.classes_ = self.classes_[0]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _validate_X_predict(self, X, check_input):\n",
    "        \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n",
    "        if check_input:\n",
    "            X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n",
    "            if issparse(X) and (X.indices.dtype != np.intc or\n",
    "                                X.indptr.dtype != np.intc):\n",
    "                raise ValueError(\"No support for np.int64 index based \"\n",
    "                                 \"sparse matrices\")\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "        if self.n_features_ != n_features:\n",
    "            raise ValueError(\"Number of features of the model must \"\n",
    "                             \"match the input. Model n_features is %s and \"\n",
    "                             \"input n_features is %s \"\n",
    "                             % (self.n_features_, n_features))\n",
    "\n",
    "        return X\n",
    "\n",
    "    def predict(self, X, check_input=True):\n",
    "        check_is_fitted(self, 'tree_')\n",
    "        X = self._validate_X_predict(X, check_input)\n",
    "        proba = self.tree_.predict(X)\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # Classification\n",
    "        if is_classifier(self):\n",
    "            if self.n_outputs_ == 1:\n",
    "                return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n",
    "\n",
    "            else:\n",
    "                predictions = np.zeros((n_samples, self.n_outputs_))\n",
    "\n",
    "                for k in range(self.n_outputs_):\n",
    "                    predictions[:, k] = self.classes_[k].take(\n",
    "                        np.argmax(proba[:, k], axis=1),\n",
    "                        axis=0)\n",
    "\n",
    "                return predictions\n",
    "\n",
    "        # Regression\n",
    "        else:\n",
    "            if self.n_outputs_ == 1:\n",
    "                return proba[:, 0]\n",
    "\n",
    "            else:\n",
    "                return proba[:, :, 0]\n",
    "\n",
    "    def apply(self, X, check_input=True):\n",
    "        check_is_fitted(self, 'tree_')\n",
    "        X = self._validate_X_predict(X, check_input)\n",
    "        return self.tree_.apply(X)\n",
    "\n",
    "    def decision_path(self, X, check_input=True):\n",
    "        X = self._validate_X_predict(X, check_input)\n",
    "        return self.tree_.decision_path(X)\n",
    "\n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        check_is_fitted(self, 'tree_')\n",
    "\n",
    "        return self.tree_.compute_feature_importances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDecisionTree():\n",
    "    def __init__(self,\n",
    "                 criterion,\n",
    "                 splitter,\n",
    "                 max_depth,\n",
    "                 min_samples_split,\n",
    "                 min_samples_leaf,\n",
    "                 min_weight_fraction_leaf,\n",
    "                 max_features,\n",
    "                 max_leaf_nodes,\n",
    "                 random_state,\n",
    "                 min_impurity_decrease,\n",
    "                 min_impurity_split,\n",
    "                 class_weight=None,\n",
    "                 presort=False):\n",
    "        self.criterion = criterion\n",
    "        self.splitter = splitter\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.min_impurity_split = min_impurity_split\n",
    "        self.class_weight = class_weight\n",
    "        self.presort = presort\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None, check_input=True,\n",
    "            X_idx_sorted=None):\n",
    "\n",
    "        random_state = check_random_state(self.random_state)\n",
    "        if check_input:\n",
    "            X = check_array(X, dtype=DTYPE, accept_sparse=\"csc\")\n",
    "            y = check_array(y, ensure_2d=False, dtype=None)\n",
    "            if issparse(X):\n",
    "                X.sort_indices()\n",
    "\n",
    "                if X.indices.dtype != np.intc or X.indptr.dtype != np.intc:\n",
    "                    raise ValueError(\"No support for np.int64 index based \"\n",
    "                                     \"sparse matrices\")\n",
    "\n",
    "        # Determine output settings\n",
    "        n_samples, self.n_features_ = X.shape\n",
    "        is_classification = is_classifier(self)\n",
    "\n",
    "        y = np.atleast_1d(y)\n",
    "        expanded_class_weight = None\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            # reshape is necessary to preserve the data contiguity against vs\n",
    "            # [:, np.newaxis] that does not.\n",
    "            y = np.reshape(y, (-1, 1))\n",
    "\n",
    "        self.n_outputs_ = y.shape[1]\n",
    "\n",
    "        if is_classification:\n",
    "            check_classification_targets(y)\n",
    "            y = np.copy(y)\n",
    "\n",
    "            self.classes_ = []\n",
    "            self.n_classes_ = []\n",
    "\n",
    "            if self.class_weight is not None:\n",
    "                y_original = np.copy(y)\n",
    "\n",
    "            y_encoded = np.zeros(y.shape, dtype=np.int)\n",
    "            for k in range(self.n_outputs_):\n",
    "                classes_k, y_encoded[:, k] = np.unique(y[:, k],\n",
    "                                                       return_inverse=True)\n",
    "                self.classes_.append(classes_k)\n",
    "                self.n_classes_.append(classes_k.shape[0])\n",
    "            y = y_encoded\n",
    "\n",
    "            if self.class_weight is not None:\n",
    "                expanded_class_weight = compute_sample_weight(\n",
    "                    self.class_weight, y_original)\n",
    "\n",
    "        else:\n",
    "            self.classes_ = [None] * self.n_outputs_\n",
    "            self.n_classes_ = [1] * self.n_outputs_\n",
    "\n",
    "        self.n_classes_ = np.array(self.n_classes_, dtype=np.intp)\n",
    "\n",
    "        if getattr(y, \"dtype\", None) != DOUBLE or not y.flags.contiguous:\n",
    "            y = np.ascontiguousarray(y, dtype=DOUBLE)\n",
    "\n",
    "        # Check parameters\n",
    "        max_depth = ((2 ** 31) - 1 if self.max_depth is None\n",
    "                     else self.max_depth)\n",
    "        max_leaf_nodes = (-1 if self.max_leaf_nodes is None\n",
    "                          else self.max_leaf_nodes)\n",
    "\n",
    "        if isinstance(self.min_samples_leaf, (numbers.Integral, np.integer)):\n",
    "            if not 1 <= self.min_samples_leaf:\n",
    "                raise ValueError(\"min_samples_leaf must be at least 1 \"\n",
    "                                 \"or in (0, 0.5], got %s\"\n",
    "                                 % self.min_samples_leaf)\n",
    "            min_samples_leaf = self.min_samples_leaf\n",
    "        else:  # float\n",
    "            if not 0. < self.min_samples_leaf <= 0.5:\n",
    "                raise ValueError(\"min_samples_leaf must be at least 1 \"\n",
    "                                 \"or in (0, 0.5], got %s\"\n",
    "                                 % self.min_samples_leaf)\n",
    "            min_samples_leaf = int(ceil(self.min_samples_leaf * n_samples))\n",
    "\n",
    "        if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n",
    "            if not 2 <= self.min_samples_split:\n",
    "                raise ValueError(\"min_samples_split must be an integer \"\n",
    "                                 \"greater than 1 or a float in (0.0, 1.0]; \"\n",
    "                                 \"got the integer %s\"\n",
    "                                 % self.min_samples_split)\n",
    "            min_samples_split = self.min_samples_split\n",
    "        else:  # float\n",
    "            if not 0. < self.min_samples_split <= 1.:\n",
    "                raise ValueError(\"min_samples_split must be an integer \"\n",
    "                                 \"greater than 1 or a float in (0.0, 1.0]; \"\n",
    "                                 \"got the float %s\"\n",
    "                                 % self.min_samples_split)\n",
    "            min_samples_split = int(ceil(self.min_samples_split * n_samples))\n",
    "            min_samples_split = max(2, min_samples_split)\n",
    "\n",
    "        min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n",
    "\n",
    "        if isinstance(self.max_features, six.string_types):\n",
    "            if self.max_features == \"auto\":\n",
    "                if is_classification:\n",
    "                    max_features = max(1, int(np.sqrt(self.n_features_)))\n",
    "                else:\n",
    "                    max_features = self.n_features_\n",
    "            elif self.max_features == \"sqrt\":\n",
    "                max_features = max(1, int(np.sqrt(self.n_features_)))\n",
    "            elif self.max_features == \"log2\":\n",
    "                max_features = max(1, int(np.log2(self.n_features_)))\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    'Invalid value for max_features. Allowed string '\n",
    "                    'values are \"auto\", \"sqrt\" or \"log2\".')\n",
    "        elif self.max_features is None:\n",
    "            max_features = self.n_features_\n",
    "        elif isinstance(self.max_features, (numbers.Integral, np.integer)):\n",
    "            max_features = self.max_features\n",
    "        else:  # float\n",
    "            if self.max_features > 0.0:\n",
    "                max_features = max(1,\n",
    "                                   int(self.max_features * self.n_features_))\n",
    "            else:\n",
    "                max_features = 0\n",
    "\n",
    "        self.max_features_ = max_features\n",
    "\n",
    "        if len(y) != n_samples:\n",
    "            raise ValueError(\"Number of labels=%d does not match \"\n",
    "                             \"number of samples=%d\" % (len(y), n_samples))\n",
    "        if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n",
    "            raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n",
    "        if max_depth <= 0:\n",
    "            raise ValueError(\"max_depth must be greater than zero. \")\n",
    "        if not (0 < max_features <= self.n_features_):\n",
    "            raise ValueError(\"max_features must be in (0, n_features]\")\n",
    "        if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):\n",
    "            raise ValueError(\"max_leaf_nodes must be integral number but was \"\n",
    "                             \"%r\" % max_leaf_nodes)\n",
    "        if -1 < max_leaf_nodes < 2:\n",
    "            raise ValueError((\"max_leaf_nodes {0} must be either None \"\n",
    "                              \"or larger than 1\").format(max_leaf_nodes))\n",
    "\n",
    "        if sample_weight is not None:\n",
    "            if (getattr(sample_weight, \"dtype\", None) != DOUBLE or\n",
    "                    not sample_weight.flags.contiguous):\n",
    "                sample_weight = np.ascontiguousarray(\n",
    "                    sample_weight, dtype=DOUBLE)\n",
    "            if len(sample_weight.shape) > 1:\n",
    "                raise ValueError(\"Sample weights array has more \"\n",
    "                                 \"than one dimension: %d\" %\n",
    "                                 len(sample_weight.shape))\n",
    "            if len(sample_weight) != n_samples:\n",
    "                raise ValueError(\"Number of weights=%d does not match \"\n",
    "                                 \"number of samples=%d\" %\n",
    "                                 (len(sample_weight), n_samples))\n",
    "\n",
    "        if expanded_class_weight is not None:\n",
    "            if sample_weight is not None:\n",
    "                sample_weight = sample_weight * expanded_class_weight\n",
    "            else:\n",
    "                sample_weight = expanded_class_weight\n",
    "\n",
    "        # Set min_weight_leaf from min_weight_fraction_leaf\n",
    "        if sample_weight is None:\n",
    "            min_weight_leaf = (self.min_weight_fraction_leaf *\n",
    "                               n_samples)\n",
    "        else:\n",
    "            min_weight_leaf = (self.min_weight_fraction_leaf *\n",
    "                               np.sum(sample_weight))\n",
    "\n",
    "        if self.min_impurity_split is not None:\n",
    "            warnings.warn(\"The min_impurity_split parameter is deprecated and\"\n",
    "                          \" will be removed in version 0.21. \"\n",
    "                          \"Use the min_impurity_decrease parameter instead.\",\n",
    "                          DeprecationWarning)\n",
    "            min_impurity_split = self.min_impurity_split\n",
    "        else:\n",
    "            min_impurity_split = 1e-7\n",
    "\n",
    "        if min_impurity_split < 0.:\n",
    "            raise ValueError(\"min_impurity_split must be greater than \"\n",
    "                             \"or equal to 0\")\n",
    "\n",
    "        if self.min_impurity_decrease < 0.:\n",
    "            raise ValueError(\"min_impurity_decrease must be greater than \"\n",
    "                             \"or equal to 0\")\n",
    "\n",
    "        allowed_presort = ('auto', True, False)\n",
    "        if self.presort not in allowed_presort:\n",
    "            raise ValueError(\"'presort' should be in {}. Got {!r} instead.\"\n",
    "                             .format(allowed_presort, self.presort))\n",
    "\n",
    "        if self.presort is True and issparse(X):\n",
    "            raise ValueError(\"Presorting is not supported for sparse \"\n",
    "                             \"matrices.\")\n",
    "\n",
    "        presort = self.presort\n",
    "        # Allow presort to be 'auto', which means True if the dataset is dense,\n",
    "        # otherwise it will be False.\n",
    "        if self.presort == 'auto':\n",
    "            presort = not issparse(X)\n",
    "\n",
    "        # If multiple trees are built on the same dataset, we only want to\n",
    "        # presort once. Splitters now can accept presorted indices if desired,\n",
    "        # but do not handle any presorting themselves. Ensemble algorithms\n",
    "        # which desire presorting must do presorting themselves and pass that\n",
    "        # matrix into each tree.\n",
    "        if X_idx_sorted is None and presort:\n",
    "            X_idx_sorted = np.asfortranarray(np.argsort(X, axis=0),\n",
    "                                             dtype=np.int32)\n",
    "\n",
    "        if presort and X_idx_sorted.shape != X.shape:\n",
    "            raise ValueError(\"The shape of X (X.shape = {}) doesn't match \"\n",
    "                             \"the shape of X_idx_sorted (X_idx_sorted\"\n",
    "                             \".shape = {})\".format(X.shape,\n",
    "                                                   X_idx_sorted.shape))\n",
    "\n",
    "        # Build tree\n",
    "        criterion = self.criterion\n",
    "        if not isinstance(criterion, Criterion):\n",
    "            if is_classification:\n",
    "                criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
    "                                                         self.n_classes_)\n",
    "            else:\n",
    "                criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
    "                                                         n_samples)\n",
    "\n",
    "        SPLITTERS = SPARSE_SPLITTERS if issparse(X) else DENSE_SPLITTERS\n",
    "\n",
    "        splitter = self.splitter\n",
    "        if not isinstance(self.splitter, Splitter):\n",
    "            splitter = SPLITTERS[self.splitter](criterion,\n",
    "                                                self.max_features_,\n",
    "                                                min_samples_leaf,\n",
    "                                                min_weight_leaf,\n",
    "                                                random_state,\n",
    "                                                self.presort)\n",
    "\n",
    "        self.tree_ = Tree(self.n_features_, self.n_classes_, self.n_outputs_)\n",
    "\n",
    "        # Use BestFirst if max_leaf_nodes given; use DepthFirst otherwise\n",
    "        if max_leaf_nodes < 0:\n",
    "            builder = DepthFirstTreeBuilder(splitter, min_samples_split,\n",
    "                                            min_samples_leaf,\n",
    "                                            min_weight_leaf,\n",
    "                                            max_depth,\n",
    "                                            self.min_impurity_decrease,\n",
    "                                            min_impurity_split)\n",
    "        else:\n",
    "            builder = BestFirstTreeBuilder(splitter, min_samples_split,\n",
    "                                           min_samples_leaf,\n",
    "                                           min_weight_leaf,\n",
    "                                           max_depth,\n",
    "                                           max_leaf_nodes,\n",
    "                                           self.min_impurity_decrease,\n",
    "                                           min_impurity_split)\n",
    "\n",
    "        builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
    "\n",
    "        if self.n_outputs_ == 1:\n",
    "            self.n_classes_ = self.n_classes_[0]\n",
    "            self.classes_ = self.classes_[0]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _validate_X_predict(self, X, check_input):\n",
    "        \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n",
    "        if check_input:\n",
    "            X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n",
    "            if issparse(X) and (X.indices.dtype != np.intc or\n",
    "                                X.indptr.dtype != np.intc):\n",
    "                raise ValueError(\"No support for np.int64 index based \"\n",
    "                                 \"sparse matrices\")\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "        if self.n_features_ != n_features:\n",
    "            raise ValueError(\"Number of features of the model must \"\n",
    "                             \"match the input. Model n_features is %s and \"\n",
    "                             \"input n_features is %s \"\n",
    "                             % (self.n_features_, n_features))\n",
    "\n",
    "        return X\n",
    "\n",
    "    def predict(self, X, check_input=True):\n",
    "        check_is_fitted(self, 'tree_')\n",
    "        X = self._validate_X_predict(X, check_input)\n",
    "        proba = self.tree_.predict(X)\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # Classification\n",
    "        if is_classifier(self):\n",
    "            if self.n_outputs_ == 1:\n",
    "                return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n",
    "\n",
    "            else:\n",
    "                predictions = np.zeros((n_samples, self.n_outputs_))\n",
    "\n",
    "                for k in range(self.n_outputs_):\n",
    "                    predictions[:, k] = self.classes_[k].take(\n",
    "                        np.argmax(proba[:, k], axis=1),\n",
    "                        axis=0)\n",
    "\n",
    "                return predictions\n",
    "\n",
    "        # Regression\n",
    "        else:\n",
    "            if self.n_outputs_ == 1:\n",
    "                return proba[:, 0]\n",
    "\n",
    "            else:\n",
    "                return proba[:, :, 0]\n",
    "\n",
    "    def apply(self, X, check_input=True):\n",
    "        check_is_fitted(self, 'tree_')\n",
    "        X = self._validate_X_predict(X, check_input)\n",
    "        return self.tree_.apply(X)\n",
    "\n",
    "    def decision_path(self, X, check_input=True):\n",
    "        X = self._validate_X_predict(X, check_input)\n",
    "        return self.tree_.decision_path(X)\n",
    "\n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        check_is_fitted(self, 'tree_')\n",
    "\n",
    "        return self.tree_.compute_feature_importances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_consistent_length(*arrays):\n",
    "    lengths = [_num_samples(X) for X in arrays if X is not None]\n",
    "    uniques = np.unique(lengths)\n",
    "    if len(uniques) > 1:\n",
    "        raise ValueError(\"Found input variables with inconsistent numbers of\"\n",
    "                         \" samples: %r\" % [int(l) for l in lengths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _weighted_sum(sample_score, sample_weight, normalize=False):\n",
    "    if normalize:\n",
    "        return np.average(sample_score, weights=sample_weight)\n",
    "    elif sample_weight is not None:\n",
    "        return np.dot(sample_score, sample_weight)\n",
    "    else:\n",
    "        return sample_score.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
    "    check_consistent_length(y_true, y_pred, sample_weight)\n",
    "    score = y_true == y_pred\n",
    "    return _weighted_sum(score, sample_weight, normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierMixin(object):\n",
    "    _estimator_type = \"classifier\"\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        return accuracy_score(y, self.predict(X), sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier(BaseDecisionTree, ClassifierMixin):\n",
    "    def __init__(self,\n",
    "                 criterion=\"gini\",\n",
    "                 splitter=\"best\",\n",
    "                 max_depth=None,\n",
    "                 min_samples_split=2,\n",
    "                 min_samples_leaf=1,\n",
    "                 min_weight_fraction_leaf=0.,\n",
    "                 max_features=None,\n",
    "                 random_state=None,\n",
    "                 max_leaf_nodes=None,\n",
    "                 min_impurity_decrease=0.,\n",
    "                 min_impurity_split=None,\n",
    "                 class_weight=None,\n",
    "                 presort=False):\n",
    "        super(DecisionTreeClassifier, self).__init__(\n",
    "            criterion=criterion,\n",
    "            splitter=splitter,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_features=max_features,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            class_weight=class_weight,\n",
    "            random_state=random_state,\n",
    "            min_impurity_decrease=min_impurity_decrease,\n",
    "            min_impurity_split=min_impurity_split,\n",
    "            presort=presort)\n",
    "    def fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None):\n",
    "        super(DecisionTreeClassifier, self).fit(\n",
    "            X, y,\n",
    "            sample_weight=sample_weight,\n",
    "            check_input=check_input,\n",
    "            X_idx_sorted=X_idx_sorted)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X, check_input=True):\n",
    "        check_is_fitted(self, 'tree_')\n",
    "        X = self._validate_X_predict(X, check_input)\n",
    "        proba = self.tree_.predict(X)\n",
    "\n",
    "        if self.n_outputs_ == 1:\n",
    "            proba = proba[:, :self.n_classes_]\n",
    "            normalizer = proba.sum(axis=1)[:, np.newaxis]\n",
    "            normalizer[normalizer == 0.0] = 1.0\n",
    "            proba /= normalizer\n",
    "\n",
    "            return proba\n",
    "\n",
    "        else:\n",
    "            all_proba = []\n",
    "\n",
    "            for k in range(self.n_outputs_):\n",
    "                proba_k = proba[:, k, :self.n_classes_[k]]\n",
    "                normalizer = proba_k.sum(axis=1)[:, np.newaxis]\n",
    "                normalizer[normalizer == 0.0] = 1.0\n",
    "                proba_k /= normalizer\n",
    "                all_proba.append(proba_k)\n",
    "\n",
    "            return all_proba\n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "\n",
    "        if self.n_outputs_ == 1:\n",
    "            return np.log(proba)\n",
    "\n",
    "        else:\n",
    "            for k in range(self.n_outputs_):\n",
    "                proba[k] = np.log(proba[k])\n",
    "\n",
    "            return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
